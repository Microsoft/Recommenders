{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "System version: 3.6.11 | packaged by conda-forge | (default, Nov 27 2020, 18:51:43) \n[GCC Clang 11.0.0]\nPandas version: 1.1.5\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from reco_utils.common.python_utils import binarize\n",
    "from reco_utils.common.timer import Timer\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_stratified_split\n",
    "from reco_utils.evaluation.python_evaluation import (\n",
    "    map_at_k,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    "    rmse,\n",
    "    mae,\n",
    "    logloss,\n",
    "    rsquared,\n",
    "    exp_var,\n",
    "    get_top_k_items\n",
    ")\n",
    "from reco_utils.recommender.fbt.fbt import FBT\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download and use the MovieLens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:01<00:00, 3.56kKB/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_id  item_id  item_id_name\n",
       "0      196      242  Kolya (1996)\n",
       "1       63      242  Kolya (1996)\n",
       "2      226      242  Kolya (1996)\n",
       "3      154      242  Kolya (1996)\n",
       "4      306      242  Kolya (1996)"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>item_id_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>242</td>\n      <td>Kolya (1996)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>63</td>\n      <td>242</td>\n      <td>Kolya (1996)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>226</td>\n      <td>242</td>\n      <td>Kolya (1996)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>154</td>\n      <td>242</td>\n      <td>Kolya (1996)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>306</td>\n      <td>242</td>\n      <td>Kolya (1996)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "col_user = 'user_id'\n",
    "col_item = 'item_id'\n",
    "col_item_name = f'{col_item}_name'\n",
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=(col_user, col_item),\n",
    "    title_col=col_item_name\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split the data using the python random splitter provided in utilities:\n",
    "\n",
    "We split the full dataset into a `train` and `test` dataset to evaluate performance of the algorithm against a held-out set not seen during training. Because FBT generates recommendations based on user preferences, all users that are in the test set must also exist in the training set. For this case, we can use the provided `python_stratified_split` function which holds out a percentage (in this case 25%) of items from each user, but ensures all users are in both `train` and `test` datasets. Other options are available in the `dataset.python_splitters` module which provide more control over how the split occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_stratified_split(data, \n",
    "                                      ratio=0.75, \n",
    "                                      col_user=col_user, \n",
    "                                      col_item=col_item, \n",
    "                                      seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTrain:\nTotal Ratings: 74992\nUnique Users: 943\nUnique Items: 1601\n\nTest:\nTotal Ratings: 25008\nUnique Users: 943\nUnique Items: 1532\n\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Train:\n",
    "Total Ratings: {train_total}\n",
    "Unique Users: {train_users}\n",
    "Unique Items: {train_items}\n",
    "\n",
    "Test:\n",
    "Total Ratings: {test_total}\n",
    "Unique Users: {test_users}\n",
    "Unique Items: {test_items}\n",
    "\"\"\".format(\n",
    "    train_total=len(train),\n",
    "    train_users=len(train[col_user].unique()),\n",
    "    train_items=len(train[col_item].unique()),\n",
    "    test_total=len(test),\n",
    "    test_users=len(test[col_user].unique()),\n",
    "    test_items=len(test[col_item].unique()),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Train the FBT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s')\n",
    "\n",
    "col_score = 'score'\n",
    "model = FBT(\n",
    "    col_user=col_user,\n",
    "    col_item=col_item,\n",
    "    col_score=col_score,\n",
    "    num_recos=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-05-24 12:07:26,533 INFO     Check dataframe is of the type, schema we expect\n",
      "2021-05-24 12:07:26,561 INFO     De-duplicating the user-item counts\n",
      "2021-05-24 12:07:29,271 INFO     Done training\n",
      "Took 2.766911569982767 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit(train)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-05-24 12:07:41,444 INFO     Calculating recommendation scores\n",
      "2021-05-24 12:07:45,845 INFO     De-duplicating the user-item counts\n",
      "/Users/prasanna/opt/anaconda3/envs/reco_base/lib/python3.6/site-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "Took 5.924376523995306 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "    topk_remove_seen = model.recommend_k_items(test=test, \n",
    "                                               top_k=10, \n",
    "                                               remove_seen=True, \n",
    "                                               train=train)\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-05-24 12:07:57,584 INFO     Calculating recommendation scores\n",
      "Took 4.818754572013859 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "    topk_keep_seen = model.recommend_k_items(test=test, top_k=10, remove_seen=False)\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_id  item_id      score  rank\n",
       "0        1       98  55.149254     1\n",
       "1        1       56  50.283582     2\n",
       "2        1       69  47.925373     3\n",
       "3        1      423  47.720588     4\n",
       "4        1      204  46.970149     5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>score</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>98</td>\n      <td>55.149254</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>56</td>\n      <td>50.283582</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>69</td>\n      <td>47.925373</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>423</td>\n      <td>47.720588</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>204</td>\n      <td>46.970149</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "topk_remove_seen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_id  item_id      score  rank\n",
       "0        1       50  66.735294     1\n",
       "1        1      181  61.397059     2\n",
       "2        1      174  59.544118     3\n",
       "3        1        1  56.985294     4\n",
       "4        1       98  55.149254     5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>score</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>50</td>\n      <td>66.735294</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>181</td>\n      <td>61.397059</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>174</td>\n      <td>59.544118</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>56.985294</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>98</td>\n      <td>55.149254</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "topk_keep_seen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-05-24 12:08:15,401 INFO     Calculating recommendation scores\n",
      "Took 3.4837634110008366 seconds for prediction.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_id  item_id      score\n",
       "0        1        1  56.985294\n",
       "1        1        2  23.757576\n",
       "2        1        3  16.815385\n",
       "3        1        4  35.537313\n",
       "4        1        5  17.621212"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>56.985294</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>23.757576</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>16.815385</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>35.537313</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>17.621212</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "with Timer() as predict_time:\n",
    "    all_recos = model.predict(test)\n",
    "print(\"Took {} seconds for prediction.\".format(predict_time.interval))\n",
    "all_recos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         item_id  score\n0              1    395\n1488           2     95\n2829           3     73\n4128           4    161\n5548           5     68\n...          ...    ...\n1597039     1673      1\n1597196     1676      1\n1597274     1678      1\n1597355     1679      1\n1597436     1680      1\n\n[1601 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(model.item_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         item_id  item_id_paired  score\n",
       "1              1               2     61\n",
       "2              1               3     51\n",
       "3              1               4     91\n",
       "4              1               5     41\n",
       "5              1               6      7\n",
       "...          ...             ...    ...\n",
       "1597431     1680            1313      1\n",
       "1597432     1680            1395      1\n",
       "1597433     1680            1607      1\n",
       "1597434     1680            1678      1\n",
       "1597435     1680            1679      1\n",
       "\n",
       "[1595836 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>item_id_paired</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1597431</th>\n      <td>1680</td>\n      <td>1313</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1597432</th>\n      <td>1680</td>\n      <td>1395</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1597433</th>\n      <td>1680</td>\n      <td>1607</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1597434</th>\n      <td>1680</td>\n      <td>1678</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1597435</th>\n      <td>1680</td>\n      <td>1679</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1595836 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model._model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   user_id  item_id      score  rank                       item_id_name\n0        1       98  55.149254     1   Silence of the Lambs, The (1991)\n1        1       56  50.283582     2                Pulp Fiction (1994)\n2        1       69  47.925373     3                Forrest Gump (1994)\n3        1      423  47.720588     4  E.T. the Extra-Terrestrial (1982)\n4        1      204  46.970149     5          Back to the Future (1985)\n5        1      288  46.941176     6                      Scream (1996)\n6        1      117  44.597015     7                   Rock, The (1996)\n7        1      294  43.166667     8                   Liar Liar (1997)\n8        1      183  42.939394     9                       Alien (1979)\n9        1      238  42.358209    10             Raising Arizona (1987)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>score</th>\n      <th>rank</th>\n      <th>item_id_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>98</td>\n      <td>55.149254</td>\n      <td>1</td>\n      <td>Silence of the Lambs, The (1991)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>56</td>\n      <td>50.283582</td>\n      <td>2</td>\n      <td>Pulp Fiction (1994)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>69</td>\n      <td>47.925373</td>\n      <td>3</td>\n      <td>Forrest Gump (1994)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>423</td>\n      <td>47.720588</td>\n      <td>4</td>\n      <td>E.T. the Extra-Terrestrial (1982)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>204</td>\n      <td>46.970149</td>\n      <td>5</td>\n      <td>Back to the Future (1985)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>288</td>\n      <td>46.941176</td>\n      <td>6</td>\n      <td>Scream (1996)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>117</td>\n      <td>44.597015</td>\n      <td>7</td>\n      <td>Rock, The (1996)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>294</td>\n      <td>43.166667</td>\n      <td>8</td>\n      <td>Liar Liar (1997)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>183</td>\n      <td>42.939394</td>\n      <td>9</td>\n      <td>Alien (1979)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>238</td>\n      <td>42.358209</td>\n      <td>10</td>\n      <td>Raising Arizona (1987)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "topk_remove_seen_with_titles = (\n",
    "    topk_remove_seen.merge((\n",
    "        data.loc[:, [col_item, col_item_name]]\n",
    "            .drop_duplicates()\n",
    "            .set_index(col_item)\n",
    "    ), on=col_item, how='inner')\n",
    "    .sort_values(by=[col_user, col_score], ascending=[True, False])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "        \n",
    "display(topk_remove_seen_with_titles.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Evaluate how well FBT performs\n",
    "\n",
    "We evaluate how well FBT performs for a few common ranking metrics provided in the `python_evaluation` module in reco_utils. We will consider the Mean Average Precision (MAP), Normalized Discounted Cumalative Gain (NDCG), Precision, and Recall for the top-k items per user we computed with FBT. User and item column names are specified in each evaluation method. DInce FBT does not have ratings information, we create a dummy column with all values set to 1.0 so as to conform to the metrics signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.044028595315000515"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "test['rating'] = 1\n",
    "eval_map_k = map_at_k(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score,k=TOP_K)\n",
    "eval_map_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.2443432424633656"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "eval_ndcg = ndcg_at_k(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score, k=TOP_K)\n",
    "eval_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.2292682926829268"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "eval_precision = precision_at_k(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score, k=TOP_K)\n",
    "eval_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.09436047878760673"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "eval_recall = recall_at_k(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score, k=TOP_K)\n",
    "eval_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "65.1847870130108"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "eval_rmse = rmse(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score)\n",
    "eval_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "62.78606036179992"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "eval_mae = mae(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score)\n",
    "eval_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model:\t\nTop K:\t10\nMAP:\t0.044029\nNDCG:\t0.244343\nPrecision@K:\t0.229268\nRecall@K:\t0.094360\nRMSE:\t65.184787\nMAE:\t62.786060\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:\\t\",\n",
    "      \"Top K:\\t%d\" % TOP_K,\n",
    "      \"MAP:\\t%f\" % eval_map_k,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall,\n",
    "      \"RMSE:\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t%f\" % eval_mae,\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   user_id  item_id               item_id_name      score  rank\n0        1       49                I.Q. (1994)        NaN   NaN\n1        1       69        Forrest Gump (1994)  47.925373   3.0\n2        1      221  Breaking the Waves (1996)        NaN   NaN\n3        1        5             Copycat (1995)        NaN   NaN\n4        1      139       Love Bug, The (1969)        NaN   NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>item_id_name</th>\n      <th>score</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>49</td>\n      <td>I.Q. (1994)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>69</td>\n      <td>Forrest Gump (1994)</td>\n      <td>47.925373</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>221</td>\n      <td>Breaking the Waves (1996)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>5</td>\n      <td>Copycat (1995)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>139</td>\n      <td>Love Bug, The (1969)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Now let's look at the results for a specific user\n",
    "user_id = 1\n",
    "\n",
    "ground_truth = test[test[col_user]==user_id]\n",
    "prediction = topk_remove_seen[topk_remove_seen[col_user]==user_id].sort_values(by=col_score, ascending=False)[:TOP_K]\n",
    "test_user_movie_watched_prediction = (\n",
    "    pd.merge(ground_truth, prediction, on=[col_user, col_item], how='left')\n",
    "      .drop(columns=['rating'])\n",
    ")\n",
    "display(test_user_movie_watched_prediction.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that one of the movies from the test set was recovered by the model's top-k recommendations, however the others were not. Offline evaluations are difficult as they can only use what was seen previously in the test set and may not represent the user's actual preferences across the entire set of items. Adjustments to how the data is split, algorithm is used and hyper-parameters can improve the results here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "map",
       "data": 0.044028595315000515,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "map",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "ndcg",
       "data": 0.2443432424633656,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "ndcg",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "precision",
       "data": 0.2292682926829268,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "precision",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "recall",
       "data": 0.09436047878760673,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "recall",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "train_time",
       "data": 2.766911569982767,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "train_time",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "test_time",
       "data": 4.818754572013859,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "test_time",
       "data": true,
       "display": false
      }
     }
    }
   ],
   "source": [
    "# Record results with papermill for tests - ignore this cell\n",
    "sb.glue(\"map\", eval_map_k)\n",
    "sb.glue(\"ndcg\", eval_ndcg)\n",
    "sb.glue(\"precision\", eval_precision)\n",
    "sb.glue(\"recall\", eval_recall)\n",
    "sb.glue(\"train_time\", train_time.interval)\n",
    "sb.glue(\"test_time\", test_time.interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "name": "python3611jvsc74a57bd098169291db0c76b5a29ac985497b93ea6e9ffb789b0c6c3e8a1bf753f6a69f0f",
   "display_name": "Python 3.6.11 64-bit ('reco_base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
jobs:

- job: ${{ parameters.name }}
  pool: ${{ parameters.pool }}
  strategy:
    matrix:
      Python36-cpu:
        python.version: '3.6'
        mode: 
        condafile: conda_bare.yaml
      Python36-spark:
        python.version: '3.6'
        mode: --pyspark
        condafile: conda_pyspark.yaml

    maxParallel: 4

  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '$(python.version)'
      architecture: 'x64'
 
  -  bash: echo "##vso[task.prependpath]$CONDA/bin"
     condition: eq(variables['Agent.OS'], 'Darwin')
     displayName: Add conda to PATH (Mac)

  -  bash: echo "##vso[task.prependpath]/usr/share/miniconda/bin"
     condition: eq(variables['Agent.OS'], 'Linux')
     displayName: Add conda to PATH (Linux)

  -  bash: ./scripts/generate_conda_file.sh $(mode)
     displayName: generate yaml
    
  -  bash: |
      conda env create --quiet --name Recommender --file $(condafile)
      source activate Recommender
      pip install pytest
     displayName: Create and activate anaconda environment

  -  bash: |
      python -m pytest --junitxml=unit/test-results-smoke-cpu.xml tests/smoke/test_notebooks_python.py
      python -m pytest --junitxml=unit/test-results-integration-cpu.xml tests/integration/test_notebooks_python.py
     displayName: 'Unit tests - CPU'
     condition: eq(variables['mode'], '')

  -  bash: |
      python -m pytest --junitxml=unit/test-results-smoke-pyspark.xml tests/smoke/test_notebooks_pyspark.py
      python -m pytest --junitxml=unit/test-results-integration-pyspark.xml tests/integration/test_notebooks_pyspark.py
     displayName: 'Unit tests - PySpark'
     condition: eq(variables['mode'], '--pyspark')


  - task: PublishTestResults@2
    inputs:
      testResultsFiles: '**/test-results.xml'
      testRunTitle: 'Python $(python.version)'
    condition: succeededOrFailed()

jobs:

- job: ${{ parameters.name }}
  pool: ${{ parameters.pool }}
  strategy:
    matrix:
      Python36-cpu:
        python.version: '3.6'
        args: 
        mode: python
        condafile: conda_bare.yaml
      # disabled pyspark since we're running out-of-memory
      # Python36-spark:
        # python.version: '3.6'
        # args: --pyspark
        # mode: pyspark
        # condafile: conda_pyspark.yaml

    maxParallel: 4

  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '$(python.version)'
      architecture: 'x64'
 
  -  bash: echo "##vso[task.prependpath]$CONDA/bin"
     condition: eq(variables['Agent.OS'], 'Darwin')
     displayName: Add conda to PATH (Mac)

  -  bash: echo "##vso[task.prependpath]/usr/share/miniconda/bin"
     condition: eq(variables['Agent.OS'], 'Linux')
     displayName: Add conda to PATH (Linux)

  -  bash: ./scripts/generate_conda_file.sh $(args)
     displayName: generate yaml
    
  -  bash: |
      conda env create --quiet --name Recommender --file $(condafile)
     displayName: Create and activate anaconda environment

  -  bash: |
      source activate Recommender
      pip install pytest
      python -m pytest --junitxml=unit/test-results-smoke-$(mode).xml tests/smoke/test_notebooks_$(mode).py
      python -m pytest --junitxml=unit/test-results-integration-$(mode).xml tests/integration/test_notebooks_$(mode).py
     displayName: 'Unit tests'


  - task: PublishTestResults@2
    inputs:
      testResultsFiles: '**/test-results*.xml'
      testRunTitle: 'Python $(python.version)'
    condition: succeededOrFailed()

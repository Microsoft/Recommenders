{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LGBM Recommendation Model on MovieLens\n",
    "## Using Azure Machine Learning service (Python, CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml.core version: 1.0.18\n",
      "reco_utils version: 2019.05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import lightgbm as lgb\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from ipywidgets import interact\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Experiment, Run, Workspace\n",
    "from azureml.core.compute import AksCompute, AmlCompute, ComputeTarget\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.image import Image\n",
    "from azureml.core.image.container import ContainerImage\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.widgets import RunDetails\n",
    "print(\"azureml.core version: {}\".format(azureml.core.VERSION))\n",
    "\n",
    "sys.path.append('../..')\n",
    "import reco_utils\n",
    "from reco_utils.dataset.movielens import load_pandas_df\n",
    "from reco_utils.dataset.movielens import GENRES\n",
    "print(\"reco_utils version: {}\".format(reco_utils.VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\T-DARZHA\\Downloads\\config.json\n"
     ]
    }
   ],
   "source": [
    "# Point to the path of the config file from Azure portal\n",
    "ws = Workspace.from_config(path='~/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General variables\n",
    "COL_USER = 'UserID'\n",
    "COL_ITEM = 'ItemID'\n",
    "COL_RATING = 'Rating'\n",
    "COL_TIMESTAMP = 'Timestamp'\n",
    "COL_TITLE = 'Title'\n",
    "COL_GENRE = 'Genre'\n",
    "COL_YEAR = 'Year'\n",
    "\n",
    "HEADER = (COL_USER, COL_ITEM, COL_RATING, COL_TIMESTAMP)\n",
    "\n",
    "TOP_K = 10\n",
    "DATA_SIZE = '1m'\n",
    "\n",
    "# AML Experiment config\n",
    "EXPERIMENT_NAME = 'movielens-lgbm'\n",
    "PIP_PACKAGES = ['azureml-sdk', 'pandas', 'sklearn', 'tqdm', 'lightgbm']\n",
    "\n",
    "# AML Compute config\n",
    "CLUSTER_NAME = 'recocluster'\n",
    "VM_SIZE = 'STANDARD_D2_V2'\n",
    "MIN_NODES = 0\n",
    "MAX_NODES = 1\n",
    "\n",
    "# AML Image config\n",
    "IMAGE_NAME = 'lgbmnew{}'.format(DATA_SIZE)\n",
    "\n",
    "# AML Model config\n",
    "MODEL_NAME = 'lgbm_model.model'\n",
    "MODEL_PATH = 'outputs/{}'.format(MODEL_NAME)\n",
    "\n",
    "# AKS config\n",
    "AKS_NAME = 'akscompute'\n",
    "AKS_SERVICE = 'aksrecolgbmnew{}'.format(DATA_SIZE)\n",
    "\n",
    "CURRENT_DIR = os.path.abspath('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TemporaryDirectory 'C:\\\\Users\\\\T-DARZHA\\\\AppData\\\\Local\\\\Temp\\\\tmp8h9uewwh'>\n"
     ]
    }
   ],
   "source": [
    "os.chdir('~/recommenders/notebooks/00_quick_start')\n",
    "TEMP_DIR = TemporaryDirectory()\n",
    "print(TEMP_DIR)\n",
    "def make_temp(name):\n",
    "    return os.path.join(TEMP_DIR.name, name)\n",
    "\n",
    "# copy reco_utils dependency to temp dir\n",
    "shutil.copytree(os.path.join('..', '..', 'reco_utils'), make_temp('reco_utils'))\n",
    "\n",
    "# it's necessary to move to this directory for the image to be built properly\n",
    "os.chdir(TEMP_DIR.name)\n",
    "\n",
    "TRAIN_FILE = make_temp('train.py')\n",
    "ENTRY_SCRIPT = make_temp('entry.py')\n",
    "CONDA_FILE = make_temp('conda.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found compute target\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=CLUSTER_NAME)\n",
    "    print(\"Found compute target\")\n",
    "except:\n",
    "    print(\"Creating compute target\")\n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=VM_SIZE,\n",
    "        min_nodes=MIN_NODES,\n",
    "        max_nodes=MAX_NODES\n",
    "    )\n",
    "    \n",
    "    # Create the cluster with the specified name and configuration\n",
    "    compute_target = ComputeTarget.create(ws, CLUSTER_NAME, compute_config)\n",
    "    \n",
    "    # Wait for the cluster to complete, show the output log\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"\"\"\n",
    "\n",
    "import sys, os\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from reco_utils.dataset.movielens import load_pandas_df\n",
    "from reco_utils.dataset.movielens import GENRES\n",
    "from reco_utils.dataset.python_splitters import python_random_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "df = load_pandas_df(genres_col=\"genre\")\n",
    "\n",
    "genre_cols = []\n",
    "for genre in GENRES:\n",
    "    genre_col = 'genre_' + genre\n",
    "    df[genre_col] = df['genre'].apply(lambda x: genre in x).astype(int)\n",
    "    genre_cols.append(genre_col)\n",
    "\n",
    "# normalize genres for each user\n",
    "users = df.drop(['itemID', 'rating', 'timestamp', 'genre'], axis=1).groupby('userID').sum()\n",
    "users = users.div(users.sum(axis=1), axis=0)\n",
    "\n",
    "all_data = df[['userID','itemID', 'rating', 'genre']].set_index('userID').join(users)\n",
    "all_data['itemID'] = all_data['itemID'].astype('category')\n",
    "\n",
    "movie_genre_cols = []\n",
    "for genre in GENRES:\n",
    "    genre_col = 'movie_genre_' + genre\n",
    "    all_data[genre_col] = all_data['genre'].apply(lambda x: genre in x).astype(int)\n",
    "    movie_genre_cols.append(genre_col)\n",
    "    \n",
    "MAX_LEAF = 64\n",
    "MIN_DATA = 20\n",
    "NUM_OF_TREES = 100\n",
    "TREE_LEARNING_RATE = 0.15\n",
    "EARLY_STOPPING_ROUNDS = 20\n",
    "METRIC = 'rmse'\n",
    "SIZE = \"sample\"\n",
    "    \n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': \"regression\",\n",
    "    'metric': METRIC,\n",
    "    'num_leaves': MAX_LEAF,\n",
    "    'min_data': MIN_DATA,\n",
    "    'boost_from_average': True,\n",
    "    'num_threads': 20,\n",
    "    'feature_fraction': 0.8,\n",
    "    'learning_rate': TREE_LEARNING_RATE,\n",
    "}\n",
    "\n",
    "# split data to 3 sets\n",
    "train, test = python_random_split(all_data, ratio=[.7, .3])\n",
    "test, validate = python_random_split(test, ratio=[.7, .3])\n",
    "\n",
    "cols = genre_cols + movie_genre_cols + [\"itemID\"]\n",
    "\n",
    "train_x = train[cols]\n",
    "train_y = train['rating']\n",
    "test_x = test[cols]\n",
    "test_y = test['rating']\n",
    "validate_x = validate[cols]\n",
    "validate_y = validate['rating']\n",
    "\n",
    "lgb_train = lgb.Dataset(train_x, train_y, params=params)\n",
    "lgb_test = lgb.Dataset(test_x, test_y, reference=lgb_train)\n",
    "lgb_validate = lgb.Dataset(validate_x, validate_y, reference=lgb_train)\n",
    "\n",
    "lgb_model = lgb.train(params,\n",
    "                      lgb_train,\n",
    "                      num_boost_round=NUM_OF_TREES,\n",
    "                      early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "                      valid_sets=lgb_validate)\n",
    "\n",
    "item_rows = all_data[movie_genre_cols + [\"itemID\"]].drop_duplicates().reset_index(drop=True)\n",
    "item_rows['key'] = 0\n",
    "\n",
    "joblib.dump(lgb_model, filename='outputs/lgbm_model.model')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open(TRAIN_FILE, 'w') as f:\n",
    "    f.writelines(train_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Estimator(source_directory=TEMP_DIR.name,\n",
    "                compute_target=compute_target,\n",
    "                entry_script=os.path.basename(TRAIN_FILE),\n",
    "                pip_packages=PIP_PACKAGES)\n",
    "\n",
    "# create experiment\n",
    "exp = Experiment(workspace=ws, name=EXPERIMENT_NAME)\n",
    "run = exp.submit(config=est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>movielens-lgbm</td><td>movielens-lgbm_1566223971_2161c775</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/03909a66-bef8-4d52-8e9a-a346604e0902/resourceGroups/reco-garage-demo/providers/Microsoft.MachineLearningServices/workspaces/notes_test/experiments/movielens-lgbm/runs/movielens-lgbm_1566223971_2161c775\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: movielens-lgbm,\n",
       "Id: movielens-lgbm_1566223971_2161c775,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5ab7b12b7044eba77c80eba14b42ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Get metrics\n",
    "metrics = run.get_metrics()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm_model.model\tlgbm_model.model:13\t13\n"
     ]
    }
   ],
   "source": [
    "# Register the model\n",
    "model = run.register_model(model_name=MODEL_NAME, model_path=MODEL_PATH)\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy SAR Recommendation Webservice\n",
    "## Using Azure Machine Learning service (Local, AKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_file = \"\"\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from reco_utils.dataset.movielens import load_pandas_df\n",
    "from reco_utils.dataset.movielens import GENRES\n",
    "import lightgbm as lgb\n",
    "from azureml.core.model import Model\n",
    "\n",
    "TOP_K = 10\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path('{MODEL_NAME}')\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    global items_df\n",
    "    df = load_pandas_df(size='1m', \n",
    "                        header=({HEADER}), \n",
    "                        title_col='Title', \n",
    "                        genres_col='Genre', \n",
    "                        year_col='Year')\n",
    "    items_df = (df[['ItemID', 'Title', 'Genre', 'Year']]\n",
    "                .dropna()\n",
    "                .drop_duplicates()\n",
    "                .set_index('ItemID'))\n",
    "    genre_cols = []\n",
    "    for genre in GENRES:\n",
    "        genre_col = 'genre_' + genre\n",
    "        df[genre_col] = df['Genre'].apply(lambda x: genre in x).astype(int)\n",
    "        genre_cols.append(genre_col)\n",
    "    users = df.drop(['ItemID', 'Rating', 'Timestamp', 'Genre'], axis=1).groupby('UserID').sum()\n",
    "    users = users.div(users.sum(axis=1), axis=0)\n",
    "    all_data = df[['UserID', 'ItemID', 'Rating', 'Genre']].set_index('UserID').join(users)\n",
    "    all_data['ItemID'] = all_data['ItemID'].astype('category')\n",
    "    movie_genre_cols = []\n",
    "    for genre in GENRES:\n",
    "        genre_col = 'movie_genre_' + genre\n",
    "        all_data[genre_col] = all_data['Genre'].apply(lambda x: genre in x).astype(int)\n",
    "        movie_genre_cols.append(genre_col)\n",
    "    global item_rows\n",
    "    item_rows = all_data[movie_genre_cols + [\"ItemID\"]].drop_duplicates().reset_index(drop=True)\n",
    "    item_rows['key'] = 0\n",
    "\n",
    "def run(data):\n",
    "    try:\n",
    "        df = pd.read_json(data, typ='series')\n",
    "        test_df = pd.DataFrame(data=df.to_dict(), index=[0])\n",
    "        test_df = pd.merge(test_df, item_rows, on='key')\n",
    "        test_df['prediction'] = model.predict(test_df)\n",
    "        top_result = test_df.sort_values(by='prediction', ascending=False).head(10)\n",
    "        top_result.drop(top_result.iloc[:,1:40], inplace = True, axis = 1)\n",
    "        return top_result.join(items_df, on='ItemID').to_dict()\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "        \n",
    "\"\"\".format(TOP_K=TOP_K, \n",
    "           MODEL_NAME=MODEL_NAME, \n",
    "           DATA_SIZE=DATA_SIZE, \n",
    "           HEADER=HEADER, \n",
    "           COL_USER=COL_USER, \n",
    "           COL_ITEM=COL_ITEM, \n",
    "           COL_TITLE=COL_TITLE, \n",
    "           COL_GENRE=COL_GENRE, \n",
    "           COL_YEAR=COL_YEAR,\n",
    "           MODEL_PATH=MODEL_PATH)\n",
    "\n",
    "with open(ENTRY_SCRIPT, 'w') as f:\n",
    "    f.writelines(entry_file)\n",
    "    \n",
    "with open(CONDA_FILE, \"w\") as f:\n",
    "    f.write(CondaDependencies.create(pip_packages=PIP_PACKAGES).serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(workspace=ws, name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Container Image\n",
      "Creating image\n",
      "Running..............................\n",
      "SucceededImage creation operation finished for image lgbmnew1m:2, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "image_config = ContainerImage.image_configuration(runtime=\"python\",\n",
    "                                                  execution_script=os.path.basename(ENTRY_SCRIPT),\n",
    "                                                  conda_file=os.path.basename(CONDA_FILE),\n",
    "                                                  dependencies=['reco_utils'])\n",
    "\n",
    "try:\n",
    "    image = Image(workspace=ws, name=IMAGE_NAME)\n",
    "    print(\"Found Image\")\n",
    "except:\n",
    "    print(\"Creating Container Image\")\n",
    "    # create the image\n",
    "    image = Image.create(workspace=ws, \n",
    "                         name=IMAGE_NAME, \n",
    "                         models=[model], \n",
    "                         image_config=image_config)\n",
    "\n",
    "    # wait for image creation to finish\n",
    "    image.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found AKS compute target\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    aks_target = ComputeTarget(workspace=ws, name=AKS_NAME)\n",
    "    print(\"Found AKS compute target\")\n",
    "except:\n",
    "    print(\"Creating AKS compute target\")\n",
    "\n",
    "    # Use the default configuration for now\n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(workspace=ws,\n",
    "                                      name=AKS_NAME,\n",
    "                                      provisioning_configuration=prov_config)\n",
    "\n",
    "    # Wait for the create process to complete\n",
    "    aks_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating AKS service\n",
      "Creating service\n",
      "Running.........\n",
      "SucceededAKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "local = False\n",
    "if local:\n",
    "    # Test locally\n",
    "    deployment_config = LocalWebservice.deploy_configuration(port=8889)\n",
    "    service = Webservice.deploy_local_from_model(workspace=ws,\n",
    "                                                 name='localservice',\n",
    "                                                 models=[model],\n",
    "                                                 image_config=image_config,\n",
    "                                                 deployment_config=deployment_config)\n",
    "else:\n",
    "    # Deploy to AKS\n",
    "    try:\n",
    "        service = AksWebservice(workspace=ws, name=AKS_SERVICE)\n",
    "        print('Found AKS service')\n",
    "    except:\n",
    "        print('Creating AKS service')\n",
    "        deployment_config = AksWebservice.deploy_configuration()\n",
    "        service = Webservice.deploy_from_image(workspace=ws,\n",
    "                                               name=AKS_SERVICE,\n",
    "                                               image=image,\n",
    "                                               deployment_config=deployment_config,\n",
    "                                               deployment_target=aks_target)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test LightGBM Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5.92MB [00:02, 4.03MB/s]                                                                                               \n"
     ]
    }
   ],
   "source": [
    "df = load_pandas_df(size=DATA_SIZE, header=HEADER, title_col=COL_TITLE, genres_col=COL_GENRE, year_col=COL_YEAR)\n",
    "df = df[[COL_ITEM, COL_TITLE, COL_GENRE, COL_YEAR]].dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9770fb971de4436ba87832f72ab3da83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='title'), Dropdown(description='genre', options=('All', 'Acti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genres = set()\n",
    "for genre_list in df[COL_GENRE].unique():\n",
    "    for genre in genre_list.split('|'):\n",
    "        genres.add(genre)\n",
    "genres = ['All'] + sorted(genres)\n",
    "\n",
    "years = ['All'] + sorted(df[COL_YEAR].unique(), reverse=True)\n",
    "\n",
    "def view(title, genre, year):\n",
    "    tmp_df = df[df[COL_TITLE].str.contains(title)].set_index(COL_ITEM)\n",
    "    if genre != 'All':\n",
    "        tmp_df = tmp_df[tmp_df[COL_GENRE].str.contains(genre)]\n",
    "    if year != 'All':\n",
    "        tmp_df = tmp_df[tmp_df[COL_YEAR] == year]\n",
    "    return tmp_df.sort_values(COL_TITLE)\n",
    "\n",
    "interact(lambda title, genre, year: view(title=title, genre=genre, year=year), title='', genre=genres, year=years);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test payload to show the format\n",
    "items = {'UserID': 0, \n",
    "           'key': 0,\n",
    "           'genre_unknown': 0,\n",
    "           'genre_Action': 0,\n",
    "           'genre_Adventure': 0,\n",
    "           'genre_Animation': 0.25,\n",
    "           'genre_Children\\'s': 0.75,\n",
    "           'genre_Comedy': 0,\n",
    "           'genre_Crime': 0,\n",
    "           'genre_Documentary': 0,\n",
    "           'genre_Drama': 0,\n",
    "           'genre_Fantasy': 0,\n",
    "           'genre_Film-Noir': 0,\n",
    "           'genre_Horror': 0,\n",
    "           'genre_Musical': 0,\n",
    "           'genre_Mystery': 0,\n",
    "           'genre_Romance': 0,\n",
    "           'genre_Sci-Fi': 0,\n",
    "           'genre_Thriller': 0,\n",
    "           'genre_War': 0,\n",
    "           'genre_Western':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Authorization': 'Bearer ve9PgvhP3jVZEdnabnbrVZOgilEAEiJy'}\n",
      "Service URI: http://52.170.115.80:80/api/v1/service/aksrecolgbmnew1m/score\n"
     ]
    }
   ],
   "source": [
    "if service.compute_type == 'AKS':\n",
    "    url = service.scoring_uri\n",
    "\n",
    "    # Setup authentication using one of the keys from service\n",
    "    headers = dict(Authorization='Bearer {}'.format(service.get_keys()[0]))\n",
    "else:\n",
    "    url = 'http://localhost:8889/score'\n",
    "    headers = None\n",
    "\n",
    "print(headers)\n",
    "print('Service URI: {}'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      UserID  ItemID  prediction  \\\n",
      "1272     0.0    2917    4.361917   \n",
      "1273     0.0     431    4.361917   \n",
      "1279     0.0     521    4.361917   \n",
      "135      0.0    3735    4.361917   \n",
      "2101     0.0    3529    4.361917   \n",
      "2179     0.0     869    4.361917   \n",
      "2214     0.0    3783    4.361917   \n",
      "2962     0.0    1598    4.361917   \n",
      "2996     0.0    3335    4.361917   \n",
      "982      0.0     293    4.361917   \n",
      "\n",
      "                                                  Title  \\\n",
      "1272                                   Body Heat (1981)   \n",
      "1273                               Carlito's Way (1993)   \n",
      "1279                           Romeo Is Bleeding (1993)   \n",
      "135                                      Serpico (1973)   \n",
      "2101             Postman Always Rings Twice, The (1981)   \n",
      "2179                                 Kansas City (1996)   \n",
      "2214                                    Croupier (1998)   \n",
      "2962                          Desperate Measures (1998)   \n",
      "2996                                   Jail Bait (1954)   \n",
      "982   Professional, The (a.k.a. Leon: The Profession...   \n",
      "\n",
      "                             Genre  Year  \n",
      "1272                Crime|Thriller  1981  \n",
      "1273                   Crime|Drama  1993  \n",
      "1279                Crime|Thriller  1993  \n",
      "135                    Crime|Drama  1973  \n",
      "2101                Crime|Thriller  1981  \n",
      "2179                         Crime  1996  \n",
      "2214                   Crime|Drama  1998  \n",
      "2962          Crime|Drama|Thriller  1998  \n",
      "2996                   Crime|Drama  1954  \n",
      "982   Crime|Drama|Romance|Thriller  1994  \n"
     ]
    }
   ],
   "source": [
    "response = requests.post(url=url, json=items, headers=headers)\n",
    "if response.status_code != 200:\n",
    "    print(response.content, response.status_code)\n",
    "else:\n",
    "    result = pd.DataFrame.from_dict(response.json(), orient='columns')\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up temporary directory\n",
    "os.chdir(CURRENT_DIR)\n",
    "TEMP_DIR.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python (reco)",
   "language": "python",
   "name": "reco_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

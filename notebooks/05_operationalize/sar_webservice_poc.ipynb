{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SAR Recommendation Model on MovieLens\n",
    "## Using Azure Machine Learning service (Python, CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml.core version: 1.0.18\n",
      "reco_utils version: 2019.05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from ipywidgets import interact\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Experiment, Run, Workspace\n",
    "from azureml.core.compute import AksCompute, AmlCompute, ComputeTarget\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.image import Image\n",
    "from azureml.core.image.container import ContainerImage\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.widgets import RunDetails\n",
    "print(\"azureml.core version: {}\".format(azureml.core.VERSION))\n",
    "\n",
    "sys.path.append('../..')\n",
    "import reco_utils\n",
    "from reco_utils.dataset.movielens import load_pandas_df\n",
    "print(\"reco_utils version: {}\".format(reco_utils.VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\T-DARZHA\\Downloads\\config.json\n"
     ]
    }
   ],
   "source": [
    "# Point to the path for the config file from Azure portal\n",
    "ws = Workspace.from_config(path='~/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General variables\n",
    "COL_USER = 'UserID'\n",
    "COL_ITEM = 'ItemID'\n",
    "COL_RATING = 'Rating'\n",
    "COL_TIMESTAMP = 'Timestamp'\n",
    "COL_TITLE = 'Title'\n",
    "COL_GENRE = 'Genre'\n",
    "COL_YEAR = 'Year'\n",
    "\n",
    "HEADER = (COL_USER, COL_ITEM, COL_RATING, COL_TIMESTAMP)\n",
    "\n",
    "TOP_K = 10\n",
    "DATA_SIZE = '1m'\n",
    "\n",
    "# AML Experiment config\n",
    "EXPERIMENT_NAME = 'movielens-sar'\n",
    "PIP_PACKAGES = ['azureml-sdk', 'pandas', 'sklearn', 'tqdm']\n",
    "\n",
    "# AML Compute config\n",
    "CLUSTER_NAME = 'recocluster'\n",
    "VM_SIZE = 'STANDARD_D2_V2'\n",
    "MIN_NODES = 0\n",
    "MAX_NODES = 1\n",
    "\n",
    "# AML Image config\n",
    "IMAGE_NAME = 'sar{}'.format(DATA_SIZE)\n",
    "\n",
    "# AML Model config\n",
    "MODEL_NAME = 'movielens_sar.model'\n",
    "MODEL_PATH = 'outputs/{}'.format(MODEL_NAME)\n",
    "\n",
    "# AKS config\n",
    "AKS_NAME = 'akscompute'\n",
    "AKS_SERVICE = 'aksrecosar{}'.format(DATA_SIZE)\n",
    "\n",
    "CURRENT_DIR = os.path.abspath('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('~/recommenders/notebooks/00_quick_start')\n",
    "TEMP_DIR = TemporaryDirectory()\n",
    "def make_temp(name):\n",
    "    return os.path.join(TEMP_DIR.name, name)\n",
    "\n",
    "# copy reco_utils dependency to temp dir\n",
    "shutil.copytree(os.path.join('..', '..', 'reco_utils'), make_temp('reco_utils'))\n",
    "\n",
    "# it's necessary to move to this directory for the image to be built properly\n",
    "os.chdir(TEMP_DIR.name)\n",
    "\n",
    "TRAIN_FILE = make_temp('train.py')\n",
    "ENTRY_SCRIPT = make_temp('entry.py')\n",
    "CONDA_FILE = make_temp('conda.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found compute target\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=CLUSTER_NAME)\n",
    "    print(\"Found compute target\")\n",
    "except:\n",
    "    print(\"Creating compute target\")\n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=VM_SIZE,\n",
    "        min_nodes=MIN_NODES,\n",
    "        max_nodes=MAX_NODES\n",
    "    )\n",
    "    \n",
    "    # Create the cluster with the specified name and configuration\n",
    "    compute_target = ComputeTarget.create(ws, CLUSTER_NAME, compute_config)\n",
    "    \n",
    "    # Wait for the cluster to complete, show the output log\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"\"\"\n",
    "\n",
    "import logging\n",
    "from time import time\n",
    "\n",
    "from azureml.core import Run\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_stratified_split\n",
    "from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from reco_utils.recommender.sar import SAR\n",
    "\n",
    "\n",
    "# get hold of the current run\n",
    "run = Run.get_context()\n",
    "run.log('data-size', '{DATA_SIZE}')\n",
    "\n",
    "header = dict(col_user='{COL_USER}', \n",
    "              col_item='{COL_ITEM}', \n",
    "              col_rating='{COL_RATING}', \n",
    "              col_timestamp='{COL_TIMESTAMP}')\n",
    "\n",
    "data = movielens.load_pandas_df(\n",
    "    size='{DATA_SIZE}',\n",
    "    header=['{COL_USER}', '{COL_ITEM}', '{COL_RATING}', '{COL_TIMESTAMP}'],\n",
    "    title_col='Title'\n",
    ")\n",
    "\n",
    "train, test = python_stratified_split(data, col_user='{COL_USER}', col_item='{COL_ITEM}')\n",
    "logging.basicConfig(level=logging.DEBUG,format='%(asctime)s %(levelname)-8s %(message)s')\n",
    "\n",
    "model = SAR(**header)\n",
    "\n",
    "# train the SAR model\n",
    "start_time = time()\n",
    "\n",
    "model.fit(train)\n",
    "\n",
    "train_time = time() - start_time\n",
    "run.log('Training time', train_time)\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "predict = model.recommend_k_items(test, remove_seen=True)\n",
    "\n",
    "# evaluate\n",
    "kwargs = dict(col_user='{COL_USER}', \n",
    "              col_item='{COL_ITEM}', \n",
    "              col_rating='{COL_RATING}', \n",
    "              col_prediction='prediction', \n",
    "              k={TOP_K})\n",
    "\n",
    "eval_map = map_at_k(test, predict, **kwargs)\n",
    "eval_ndcg = ndcg_at_k(test, predict, **kwargs)\n",
    "eval_precision = precision_at_k(test, predict, **kwargs)\n",
    "eval_recall = recall_at_k(test, predict, **kwargs)\n",
    "\n",
    "test_time = time() - start_time\n",
    "run.log('Prediction time', test_time)\n",
    "\n",
    "run.log('map', eval_map)\n",
    "run.log('ndcg', eval_ndcg)\n",
    "run.log('precision', eval_precision)\n",
    "run.log('recall', eval_recall)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(value=model, filename='{MODEL_PATH}')\n",
    "\n",
    "\"\"\".format(DATA_SIZE=DATA_SIZE,\n",
    "           COL_USER=COL_USER,\n",
    "           COL_ITEM=COL_ITEM,\n",
    "           COL_RATING=COL_RATING,\n",
    "           COL_TIMESTAMP=COL_TIMESTAMP,\n",
    "           TOP_K=TOP_K,\n",
    "           MODEL_PATH=MODEL_PATH)\n",
    "\n",
    "with open(TRAIN_FILE, 'w') as f:\n",
    "    f.writelines(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Estimator(source_directory=TEMP_DIR.name,\n",
    "                compute_target=compute_target,\n",
    "                entry_script=os.path.basename(TRAIN_FILE),\n",
    "                pip_packages=PIP_PACKAGES)\n",
    "\n",
    "# create experiment\n",
    "exp = Experiment(workspace=ws, name=EXPERIMENT_NAME)\n",
    "run = exp.submit(config=est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>movielens-sar</td><td>movielens-sar_1566226508_abd6b71f</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/03909a66-bef8-4d52-8e9a-a346604e0902/resourceGroups/reco-garage-demo/providers/Microsoft.MachineLearningServices/workspaces/notes_test/experiments/movielens-sar/runs/movielens-sar_1566226508_abd6b71f\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: movielens-sar,\n",
       "Id: movielens-sar_1566226508_abd6b71f,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417f873a91bb4316891b8f56d72f79f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data-size': '1m', 'Training time': 2.3439090251922607, 'Prediction time': 73.31194710731506, 'map': 0.06109885085588233, 'ndcg': 0.3131898943527137, 'precision': 0.28523178807947025, 'recall': 0.10598717971936468}\n"
     ]
    }
   ],
   "source": [
    "# Get metrics\n",
    "metrics = run.get_metrics()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movielens_sar.model\tmovielens_sar.model:14\t14\n"
     ]
    }
   ],
   "source": [
    "# Register the model\n",
    "model = run.register_model(model_name=MODEL_NAME, model_path=MODEL_PATH)\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy SAR Recommendation Webservice\n",
    "## Using Azure Machine Learning service (Local, AKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_file = \"\"\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "from reco_utils.dataset.movielens import load_pandas_df\n",
    "\n",
    "TOP_K = {TOP_K}\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path('{MODEL_NAME}')\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    global items_df\n",
    "    df = load_pandas_df(size='{DATA_SIZE}', \n",
    "                        header={HEADER}, \n",
    "                        title_col='{COL_TITLE}', \n",
    "                        genres_col='{COL_GENRE}', \n",
    "                        year_col='{COL_YEAR}')\n",
    "    items_df = (df[['{COL_ITEM}', '{COL_TITLE}', '{COL_GENRE}', '{COL_YEAR}']]\n",
    "                .dropna()\n",
    "                .drop_duplicates()\n",
    "                .set_index('{COL_ITEM}'))\n",
    "    \n",
    "def run(data):\n",
    "    try:\n",
    "        df = pd.read_json(data)\n",
    "        result = model.get_item_based_topk(items=df, top_k={TOP_K}, sort_top_k=True)\n",
    "        return result.join(items_df, on='{COL_ITEM}').to_dict()\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "        \n",
    "\"\"\".format(TOP_K=TOP_K, \n",
    "           MODEL_NAME=MODEL_NAME, \n",
    "           DATA_SIZE=DATA_SIZE, \n",
    "           HEADER=HEADER, \n",
    "           COL_USER=COL_USER, \n",
    "           COL_ITEM=COL_ITEM, \n",
    "           COL_TITLE=COL_TITLE, \n",
    "           COL_GENRE=COL_GENRE, \n",
    "           COL_YEAR=COL_YEAR)\n",
    "\n",
    "with open(ENTRY_SCRIPT, 'w') as f:\n",
    "    f.writelines(entry_file)\n",
    "    \n",
    "with open(CONDA_FILE, \"w\") as f:\n",
    "    f.write(CondaDependencies.create(pip_packages=PIP_PACKAGES).serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(workspace=ws, name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Container Image\n",
      "Creating image\n",
      "Running....................................\n",
      "SucceededImage creation operation finished for image sar1m1:2, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "image_config = ContainerImage.image_configuration(runtime=\"python\",\n",
    "                                                  execution_script=os.path.basename(ENTRY_SCRIPT),\n",
    "                                                  conda_file=os.path.basename(CONDA_FILE),\n",
    "                                                  dependencies=['reco_utils'])\n",
    "\n",
    "try:\n",
    "    image = Image(workspace=ws, name=IMAGE_NAME)\n",
    "    print(\"Found Image\")\n",
    "except:\n",
    "    print(\"Creating Container Image\")\n",
    "    # create the image\n",
    "    image = Image.create(workspace=ws, \n",
    "                         name=IMAGE_NAME, \n",
    "                         models=[model], \n",
    "                         image_config=image_config)\n",
    "\n",
    "    # wait for image creation to finish\n",
    "    image.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found AKS compute target\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    aks_target = ComputeTarget(workspace=ws, name=AKS_NAME)\n",
    "    print(\"Found AKS compute target\")\n",
    "except:\n",
    "    print(\"Creating AKS compute target\")\n",
    "\n",
    "    # Use the default configuration for now\n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(workspace=ws,\n",
    "                                      name=AKS_NAME,\n",
    "                                      provisioning_configuration=prov_config)\n",
    "\n",
    "    # Wait for the create process to complete\n",
    "    aks_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating AKS service\n",
      "Creating service\n",
      "Running..........\n",
      "SucceededAKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "local = False\n",
    "if local:\n",
    "    # Test locally\n",
    "    deployment_config = LocalWebservice.deploy_configuration(port=8889)\n",
    "    service = Webservice.deploy_local_from_model(workspace=ws,\n",
    "                                                 name='localservice',\n",
    "                                                 models=[model],\n",
    "                                                 image_config=image_config,\n",
    "                                                 deployment_config=deployment_config)\n",
    "else:\n",
    "    # Deploy to AKS\n",
    "    try:\n",
    "        service = AksWebservice(workspace=ws, name=AKS_SERVICE)\n",
    "        print('Found AKS service')\n",
    "    except:\n",
    "        print('Creating AKS service')\n",
    "        deployment_config = AksWebservice.deploy_configuration()\n",
    "        service = Webservice.deploy_from_image(workspace=ws,\n",
    "                                               name=AKS_SERVICE,\n",
    "                                               image=image,\n",
    "                                               deployment_config=deployment_config,\n",
    "                                               deployment_target=aks_target)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test SAR Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5.92MB [00:03, 1.70MB/s]                                                                                               \n"
     ]
    }
   ],
   "source": [
    "df = load_pandas_df(size=DATA_SIZE, header=HEADER, title_col=COL_TITLE, genres_col=COL_GENRE, year_col=COL_YEAR)\n",
    "df = df[[COL_ITEM, COL_TITLE, COL_GENRE, COL_YEAR]].dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf032e73244e4fb58135d76be92e3d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='title'), Dropdown(description='genre', options=('All', 'Acti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genres = set()\n",
    "for genre_list in df[COL_GENRE].unique():\n",
    "    for genre in genre_list.split('|'):\n",
    "        genres.add(genre)\n",
    "genres = ['All'] + sorted(genres)\n",
    "\n",
    "years = ['All'] + sorted(df[COL_YEAR].unique(), reverse=True)\n",
    "\n",
    "def view(title, genre, year):\n",
    "    tmp_df = df[df[COL_TITLE].str.contains(title)].set_index(COL_ITEM)\n",
    "    if genre != 'All':\n",
    "        tmp_df = tmp_df[tmp_df[COL_GENRE].str.contains(genre)]\n",
    "    if year != 'All':\n",
    "        tmp_df = tmp_df[tmp_df[COL_YEAR] == year]\n",
    "    return tmp_df.sort_values(COL_TITLE)\n",
    "\n",
    "interact(lambda title, genre, year: view(title=title, genre=genre, year=year), title='', genre=genres, year=years);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = {COL_ITEM: [2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service URI: http://52.170.115.80:80/api/v1/service/aksrecosar1m/score\n"
     ]
    }
   ],
   "source": [
    "if service.compute_type == 'AKS':\n",
    "    url = service.scoring_uri\n",
    "\n",
    "    # Setup authentication using one of the keys from service\n",
    "    headers = dict(Authorization='Bearer {}'.format(service.get_keys()[0]))\n",
    "else:\n",
    "    url = 'http://localhost:8889/score'\n",
    "    headers = None\n",
    "\n",
    "print('Service URI: {}'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Authorization': 'Bearer QYl3Li1T5oo9UqLgwobB6JmGGwaBCWNc'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>prediction</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3489</td>\n",
       "      <td>0.313539</td>\n",
       "      <td>Hook (1991)</td>\n",
       "      <td>Adventure|Fantasy</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3438</td>\n",
       "      <td>0.252252</td>\n",
       "      <td>Teenage Mutant Ninja Turtles (1990)</td>\n",
       "      <td>Action|Children's|Fantasy</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>673</td>\n",
       "      <td>0.240858</td>\n",
       "      <td>Space Jam (1996)</td>\n",
       "      <td>Adventure|Animation|Children's|Comedy|Fantasy</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>653</td>\n",
       "      <td>0.239852</td>\n",
       "      <td>Dragonheart (1996)</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>367</td>\n",
       "      <td>0.238462</td>\n",
       "      <td>Mask, The (1994)</td>\n",
       "      <td>Comedy|Crime|Fantasy</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2161</td>\n",
       "      <td>0.228150</td>\n",
       "      <td>NeverEnding Story, The (1984)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>0.226371</td>\n",
       "      <td>Santa Clause, The (1994)</td>\n",
       "      <td>Children's|Comedy|Fantasy</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.224670</td>\n",
       "      <td>Indian in the Cupboard, The (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2193</td>\n",
       "      <td>0.223261</td>\n",
       "      <td>Willow (1988)</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.220982</td>\n",
       "      <td>Goonies, The (1985)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  ItemID  prediction                                Title  \\\n",
       "0       0    3489    0.313539                          Hook (1991)   \n",
       "1       0    3438    0.252252  Teenage Mutant Ninja Turtles (1990)   \n",
       "2       0     673    0.240858                     Space Jam (1996)   \n",
       "3       0     653    0.239852                   Dragonheart (1996)   \n",
       "4       0     367    0.238462                     Mask, The (1994)   \n",
       "5       0    2161    0.228150        NeverEnding Story, The (1984)   \n",
       "6       0     317    0.226371             Santa Clause, The (1994)   \n",
       "7       0      60    0.224670   Indian in the Cupboard, The (1995)   \n",
       "8       0    2193    0.223261                        Willow (1988)   \n",
       "9       0    2005    0.220982                  Goonies, The (1985)   \n",
       "\n",
       "                                           Genre  Year  \n",
       "0                              Adventure|Fantasy  1991  \n",
       "1                      Action|Children's|Fantasy  1990  \n",
       "2  Adventure|Animation|Children's|Comedy|Fantasy  1996  \n",
       "3                       Action|Adventure|Fantasy  1996  \n",
       "4                           Comedy|Crime|Fantasy  1994  \n",
       "5                   Adventure|Children's|Fantasy  1984  \n",
       "6                      Children's|Comedy|Fantasy  1994  \n",
       "7                   Adventure|Children's|Fantasy  1995  \n",
       "8                       Action|Adventure|Fantasy  1988  \n",
       "9                   Adventure|Children's|Fantasy  1985  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send a request to the service\n",
    "response = requests.post(url=url, json=items, headers=headers)\n",
    "if response.status_code != 200:\n",
    "    print(response.content, response.status_code)\n",
    "else:\n",
    "    result = pd.DataFrame(response.json())\n",
    "print(headers)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up temporary directory\n",
    "os.chdir(CURRENT_DIR)\n",
    "TEMP_DIR.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python (reco)",
   "language": "python",
   "name": "reco_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
